# SpharxHub - Physical World Data Infrastructure Platform

<div align="center">

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/docker-ready-green.svg)](https://www.docker.com/)
[![Platform](https://img.shields.io/badge/platform-Linux%20%7C%20Windows-lightgrey.svg)](#)

**Building Physical World Data Infrastructure for the AI Era**

</div>

## ğŸ“‹ Project Overview

SpharxHub is an end-to-end data infrastructure platform for embodied intelligence and physical world understanding. The platform consists of three core subsystems:

- **ğŸ§  Workshop**: Physical World Data Factory - Automated pipeline from sensors to standardized datasets
- **ğŸ”¬ Deepness**: Deep Processing Production Line - Physics property injection, interaction trajectory recording, and advanced processing
- **ğŸ“Š Benchmark**: World Model Evaluation Center - Datasets, metrics, and evaluation benchmarks

Our mission is to become the "TSMC of data" for the AI era, providing high-quality, scalable physical world data solutions for embodied intelligence, robot vision, and physical simulation domains.

## ğŸ—ï¸ Overall Architecture

```
SpharxHub/
â”œâ”€â”€ workshop/           # L0-L2 Data Production Pipeline
â”‚   â”œâ”€â”€ pipelines/      # 6 processing modules (ingestâ†’qualityâ†’enhanceâ†’calibrateâ†’packâ†’deliver)
â”‚   â”œâ”€â”€ hardware/       # Hardware control (RealSense sync, calibration tools)
â”‚   â”œâ”€â”€ dashboard/      # Web monitoring panel
â”‚   â””â”€â”€ schemas/        # Data model definitions
â”‚
â”œâ”€â”€ deepness/           # L2-L4 Deep Processing
â”‚   â”œâ”€â”€ pipelines/      # Physics injection, interaction recording, evaluation export
â”‚   â”œâ”€â”€ common/         # Shared components and models
â”‚   â””â”€â”€ base/           # Base Docker images
â”‚
â””â”€â”€ benchmark/          # Evaluation Benchmark Suite
    â”œâ”€â”€ datasets/       # Standard evaluation datasets
    â”œâ”€â”€ metrics/        # Evaluation metrics and tools
    â””â”€â”€ results/        # Benchmark test results
```

## ğŸš€ Core Subsystems

### 1. Workshop - Physical World Data Factory âœ…

**Status**: Production Ready (v3.1)

Automated data collection and processing pipeline based on Intel RealSense cameras, completed features include:

- âœ… Hardware synchronization solution (3Ã—D455 camera synchronized capture)
- âœ… Real data parsing (RGB video, depth maps, IMU data extraction)
- âœ… Automated quality inspection (blur/exposure/frame drop detection)
- âœ… Semantic annotation (YOLOv8 object detection)
- âœ… Camera calibration (checkerboard intrinsic calibration)
- âœ… Dataset packaging (SHA256 hash verification)
- âœ… Web monitoring panel (Streamlit)

**Tech Stack**: Python 3.10+, Docker, OpenCV, PyTorch, YOLOv8, Intel RealSense SDK

### 2. Deepness - Deep Processing Production Line âš¡

**Status**: In Development

Advanced physical world processing platform based on Fast-SAM3D:

- ğŸ”¨ Physics property injection module (Fast-SAM3D, PyTorch3D, Open3D)
- ğŸ“ Interaction trajectory recording module (reserved)
- ğŸ“¤ Evaluation data export module (Genie Sim 3.0, NVIDIA Cosmos format)

**Tech Stack**: Fast-SAM3D, PyTorch 2.5.1, CUDA 12.1, PyTorch3D 0.7.6

### 3. Benchmark - Evaluation Center ğŸ“Š

**Status**: In Planning

Standardized evaluation platform for world models:

- ğŸ“ Evaluation dataset management
- ğŸ“ Performance metric definition
- ğŸ“Š Result analysis tools
- ğŸ”„ Benchmark testing scripts

## ğŸ› ï¸ Technical Features

### ğŸ­ Industrial Production
- **Modular Design**: Each processing stage is containerized independently, supporting plug-and-play expansion
- **Configuration Separation**: All parameters centrally managed, supporting environment variable override
- **Exception Handling**: Comprehensive logging system and error recovery mechanisms
- **Quality Assurance**: Automated quality inspection and data integrity verification

### ğŸ”§ Developer Friendly
- **Dockerized**: One-click build and deployment of all services
- **Multi-platform Support**: Linux/Windows dual-platform compatibility
- **Complete Documentation**: Detailed development documentation and usage guides
- **Test Coverage**: Unit testing and integration testing framework

### ğŸš€ High-Performance Computing
- **GPU Acceleration**: CUDA-optimized deep learning inference
- **Batch Processing Optimization**: Supports large-scale data parallel processing
- **Resource Management**: Intelligent memory and GPU memory management

## ğŸ“¦ Quick Start

### System Requirements

- **Operating System**: Ubuntu 22.04 / Windows 10+
- **Docker**: 20.10+
- **GPU**: NVIDIA GPU (optional, for deep learning modules)
- **Memory**: 16GB+ RAM
- **Storage**: 100GB+ available space

### Installation and Deployment

```bash
# Clone repository
git clone https://gitee.com/spharx/spharxhub.git
cd spharxhub

# Build Workshop system
cd workshop
docker-compose build

# Start data processing pipeline
./scripts/pipeline/run_full.sh /path/to/your/recording.bag
```

### Usage Example

```python
# Workshop data processing example
from workshop.pipelines.ingest.parser import RealSenseParser
from workshop.pipelines.quality.detector import QualityDetector

# Parse RealSense data
parser = RealSenseParser()
data = parser.parse('/path/to/recording.bag')

# Quality detection
quality_checker = QualityDetector()
report = quality_checker.analyze(data)
```

## ğŸ“Š Project Status

| Subsystem | Status | Version | Completion |
|-----------|--------|---------|------------|
| Workshop | âœ… Production Ready | v3.1 | 100% |
| Deepness | âš¡ In Development | v0.1 | 60% |
| Benchmark | ğŸ“Š In Planning | v0.0 | 20% |

**Overall Progress**: 60%

## ğŸ¤ Contribution Guidelines

We welcome contributions in various forms:

1. **Report Issues**: Submit bugs or feature requests
2. **Code Contributions**: Submit Pull Requests
3. **Documentation Improvement**: Enhance usage documentation
4. **Testing Enhancement**: Increase test coverage

Please refer to each subsystem's CONTRIBUTING.md file for specific contribution processes.

## ğŸ“š Documentation Resources

- [ğŸ“˜ Complete Workshop Documentation](workshop/README.md)
- [ğŸ”¬ Deepness Technical Documentation](deepness/README.md)
- [ğŸ“Š Benchmark Design Documentation](benchmark/README.md)
- [ğŸ“ˆ Project Progress Report](workshop/PROGRESS.md)

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸŒŸ Acknowledgements

Thanks to the following open-source projects for their contributions:

- [Intel RealSense SDK](https://github.com/IntelRealSense/librealsense)
- [YOLOv8](https://github.com/ultralytics/ultralytics)
- [Fast-SAM3D](https://github.com/wlfeng0509/Fast-SAM3D)
- [Open3D](http://www.open3d.org/)
- [PyTorch3D](https://pytorch3d.org/)

---

<div align="center">

**SpharxHub** â€”â€” Starting with Data, Ending with Intelligence

*Building Physical World Data Infrastructure for the AI Era*

</div>